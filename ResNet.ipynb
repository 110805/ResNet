{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRiR54dUHrfv/BvjQAxT99",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/110805/Retinopathy_detection/blob/master/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS752F2UECRT",
        "colab_type": "code",
        "outputId": "09dccaea-332b-4cce-d1c2-9d0d48aec24e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!git clone https://github.com/110805/Retinopathy_detection.git\n",
        "%cd Retinopathy_detection/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Retinopathy_detection'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 35153 (delta 9), reused 6 (delta 3), pack-reused 35135\u001b[K\n",
            "Receiving objects: 100% (35153/35153), 556.73 MiB | 32.03 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Checking out files: 100% (35133/35133), done.\n",
            "/content/Retinopathy_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG7i5mEfw_7N",
        "colab_type": "code",
        "outputId": "52d59d8e-efe5-4370-ddb2-82be9e007504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from dataloader import RetinopathyLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "# Hyperparameter setting\n",
        "batch_size = 4\n",
        "learning_rate = 1e-3\n",
        "epochs_18 = 10\n",
        "epochs_50 = 5\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_data = RetinopathyLoader(root='/content/Retinopathy_detection/data/', mode='train')\n",
        "test_data = RetinopathyLoader(root='/content/Retinopathy_detection/data/', mode='test')\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, pretrained=True, res_type=50):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.classify = nn.Linear(512, 5)\n",
        "\n",
        "        pretrained_model = torchvision.models.__dict__['resnet{}'.format(res_type)](pretrained=pretrained)\n",
        "        self.conv1 = pretrained_model._modules['conv1']\n",
        "        self.bn1 = pretrained_model._modules['bn1']\n",
        "        self.relu = pretrained_model._modules['relu']\n",
        "        self.maxpool = pretrained_model._modules['maxpool']\n",
        "\n",
        "        self.layer1 = pretrained_model._modules['layer1']\n",
        "        self.layer2 = pretrained_model._modules['layer2']\n",
        "        self.layer3 = pretrained_model._modules['layer3']\n",
        "        self.layer4 = pretrained_model._modules['layer4']\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        del pretrained_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classify(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "models_18 = [ResNet(pretrained=False, res_type=18), ResNet(pretrained=True, res_type=18)]\n",
        "models_50 = [ResNet(pretrained=False, res_type=50), ResNet(pretrained=True, res_type=50)]\n",
        "device = torch.device('cuda')\n",
        "\n",
        "def train(model):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "\n",
        "    for idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, labels.flatten())\n",
        "        _, preds = torch.max(outputs, 1) # the second return of max is the return of argmax\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += torch.sum(preds == labels.data.flatten())\n",
        "        if idx%1000 == 0:\n",
        "            print(idx)\n",
        "            \n",
        "    epoch_acc = 100*correct.item() / 28099    \n",
        "    print('Train Acc: {:4f}'.format(epoch_acc))\n",
        "\n",
        "    return epoch_acc\n",
        "\n",
        "def test(model, best_acc, best_model_weight):\n",
        "    # i indicates that which model we are running now\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs.float())\n",
        "\n",
        "        _, preds = torch.max(outputs, 1) # the second return of max is the return of argmax\n",
        "        correct += torch.sum(preds == labels.data.flatten())\n",
        "        if idx%1000 == 0:\n",
        "            print(idx)\n",
        "            \n",
        "    epoch_acc = 100*correct.item() / 7025    \n",
        "    print('Test Acc: {:4f}'.format(epoch_acc))\n",
        "\n",
        "    if epoch_acc > best_acc:\n",
        "        best_model_weight = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    return epoch_acc, best_model_weight\n",
        "\n",
        "model_weight = []\n",
        "legend = ['Train(w/o pretrain)', 'Test(w/o pretrain)', 'Test(w/o pretrain)', 'Test(with pretrain)']\n",
        "for i, model in enumerate(models_18):\n",
        "    best_acc = 0\n",
        "    model.to(device)\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "    weight = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(epochs_18):\n",
        "        print('Epoch {}'.format(epoch+1))\n",
        "        train_acc.append(train(model))\n",
        "        acc, weight = test(model, best_acc, weight)\n",
        "        test_acc.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "\n",
        "        print('-' * 10)\n",
        "    \n",
        "    model_weight.append(weight)\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "    plt.plot(range(epochs), train_acc, label=legend[2*i])\n",
        "    plt.plot(range(epochs), test_acc, label=legend[2*i+1])\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy(%)')\n",
        "plt.title(\"Result comparison(ResNet18)\")\n",
        "plt.legend(loc='best')\n",
        "plt.savefig(\"Result_ResNet18.png\")\n",
        "plt.show()\n",
        "\n",
        "for i, model in enumerate(models_50):\n",
        "    best_acc = 0\n",
        "    model.to(device)\n",
        "    train_acc = []\n",
        "    test_acc = []\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "    weight = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(epochs_50):\n",
        "        print('Epoch {}'.format(epoch+1))\n",
        "        train_acc.append(train(model))\n",
        "        acc, weight = test(model, best_acc, weight)\n",
        "        test_acc.append(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "\n",
        "        print('-' * 10)\n",
        "    \n",
        "    model_weight.append(weight)\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "    plt.plot(range(epochs), train_acc, label=legend[2*i])\n",
        "    plt.plot(range(epochs), test_acc, label=legend[2*i+1])\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy(%)')\n",
        "plt.title(\"Result comparison(ResNet50)\")\n",
        "plt.legend(loc='best')\n",
        "plt.savefig(\"Result_ResNet50.png\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Found 28099 images...\n",
            "> Found 7025 images...\n",
            "Epoch 1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}